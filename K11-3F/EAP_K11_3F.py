import sys
# æ›´æ›
from datetime import datetime
import json
import os
import subprocess
import pandas as pd
from ping3 import ping  # type: ignore
from tqdm import tqdm # type: ignore
import csv
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
from logging.handlers import RotatingFileHandler
from filelock import FileLock, Timeout
import warnings
import shutil
warnings.simplefilter(action='ignore', category=FutureWarning)

import configparser

# -------------------------------------------------
#  è®€å– config.iniï¼ˆå›ºå®šç”¨ .py æ‰€åœ¨è³‡æ–™å¤¾ï¼‰
# -------------------------------------------------
config = configparser.ConfigParser()

# å–å¾—ç›®å‰é€™å€‹ .py æª”æ‰€åœ¨çš„è³‡æ–™å¤¾
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# å¦‚æœä½ æª”åå°±æ˜¯ config.iniï¼Œå°±é€™æ¨£å¯«
config_path = os.path.join(BASE_DIR, "config.ini")

# å¦‚æœä½ æƒ³åˆ†ä¸åŒç·šåˆ¥ï¼Œç”¨å°ˆå±¬ iniï¼ˆä¾‹å¦‚ EAP_K11_3F.iniï¼‰ï¼Œå°±æ”¹é€™è£¡çš„æª”å
# config_path = os.path.join(BASE_DIR, "EAP_K11_3F.ini")

if not os.path.exists(config_path):
    print(f"âŒ æ‰¾ä¸åˆ°è¨­å®šæª”ï¼š{config_path}")
    sys.exit(1)

# è®€å– ini
config.read(config_path, encoding="utf-8")

# æª¢æŸ¥ Paths å€æ®µæ˜¯å¦å­˜åœ¨
if "Paths" not in config:
    print(f"âŒ è¨­å®šæª” {config_path} ç¼ºå°‘ [Paths] å€æ®µ")
    sys.exit(1)

# å–å¾—è·¯å¾‘è¨­å®š
try:
    LOG_FILE = config.get("Paths", "log_file")
    SOURCE_FILES = [
        x.strip() for x in config.get("Paths", "source_files").split(",")
        if x.strip()
    ]
except Exception as e:
    print(f"âŒ è®€å– [Paths] è¨­å®šå¤±æ•—ï¼š{e}")
    sys.exit(1)

# è¨­å®š loggingï¼ˆä½¿ç”¨ RotatingFileHandlerï¼Œæœ€å¤§ 100MBï¼Œä¸ä¿ç•™å‚™ä»½ï¼‰
log_handler = RotatingFileHandler(
    LOG_FILE,
    maxBytes=100*1024*1024,  # 100MB
    backupCount=0,           # ä¸ä¿ç•™å‚™ä»½ï¼Œé”åˆ° 100MB å¾Œæ¸…ç©ºé‡æ–°é–‹å§‹
    encoding='utf-8'
)
log_handler.setLevel(logging.INFO)
log_handler.setFormatter(logging.Formatter('%(asctime)s %(levelname)s: %(message)s'))

console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(logging.Formatter('%(asctime)s %(levelname)s: %(message)s'))

logging.basicConfig(
    level=logging.INFO,
    handlers=[log_handler, console_handler]
)


def get_status_file(path):
    """
    æ ¹æ“š CSV ä¾†æºæª”åç”¢ç”Ÿ prev_XXX.json
    """
    file_name = os.path.basename(path)
    safe_name = file_name.replace(" ", "_")
    prev_file = os.path.join(BASE_DIR, f"prev_{safe_name}.json")
    return prev_file

class Ping_EAP:
    def __init__(self, file_path):
        self.file_path = file_path
        self.ip_addresses = []
        self.device_names = []
        self.ping_results = {}

    def read_ip_addresses_from_csv(self):
        with open(self.file_path, mode='r', encoding='utf-8') as file:
            reader = csv.reader(file)
            next(reader)
            for row in reader:
                self.ip_addresses.append(row[0])
                self.device_names.append(row[3])

    def ping_host(self, ip_address, timeout_sec):
        try:
            # Windows pingï¼Œ-n 1 ä¸€æ¬¡ï¼Œ-w timeout ä»¥æ¯«ç§’ç‚ºå–®ä½
            result = subprocess.run(
                ['ping', '-n', '1', ip_address, '-w', str(timeout_sec * 1000)],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                universal_newlines=True,
                timeout=timeout_sec + 1  # çµ¦ä¸€é»é¤˜è£•
            )
            output = result.stdout

            # å¿…é ˆåŒ…å« TTL ä»£è¡¨çœŸå¯¦å›æ‡‰
            if "TTL=" in output:
                return ip_address, "alive"
            else:
                return ip_address, "dead"

        except subprocess.TimeoutExpired:
            return ip_address, "dead"
        except Exception:
            return ip_address, "dead"

    def scan_all(self):
        print("ğŸ” ç¬¬ä¸€æ¬¡å¿«é€Ÿæƒæä¸­ï¼ˆtimeout=2 ç§’ï¼‰...")
        dead_list = []

        # ç¬¬ä¸€æ¬¡å¿«é€Ÿæƒæ
        with ThreadPoolExecutor(max_workers=50) as executor:
            futures = {
                executor.submit(self.ping_host, ip, 2): ip
                for ip in self.ip_addresses
            }
            for future in tqdm(as_completed(futures), total=len(futures)):
                ip, result = future.result()
                self.ping_results[ip] = result
                if result == "dead":
                    dead_list.append(ip)

        retry_dead_list = []
        if dead_list:
            print("ğŸ” ç¬¬äºŒæ¬¡æ…¢é€Ÿé‡è©¦ä¸­ï¼ˆtimeout=8 ç§’ï¼‰...")
            with ThreadPoolExecutor(max_workers=30) as executor:
                futures = {
                    executor.submit(self.ping_host, ip, 8): ip
                    for ip in dead_list
                }
                for future in tqdm(as_completed(futures), total=len(futures)):
                    ip, result = future.result()
                    if result == "alive":
                        self.ping_results[ip] = "alive"  # è¦†è“‹ä¹‹å‰çš„ dead
                    else:
                        retry_dead_list.append(ip)

        # ç¬¬ä¸‰æ¬¡ä½¿ç”¨ Device_Name é‡è©¦
        if retry_dead_list:
            print("ğŸ” ç¬¬ä¸‰æ¬¡ä½¿ç”¨ Device_Name é‡è©¦ä¸­ï¼ˆtimeout=8 ç§’ï¼‰...")
            success_by_device = []   # æš«å­˜æˆåŠŸè¨Šæ¯
            fail_by_device = []      # æš«å­˜å¤±æ•—è¨Šæ¯

            with ThreadPoolExecutor(max_workers=20) as executor:
                futures = {}
                for ip in retry_dead_list:
                    try:
                        idx = self.ip_addresses.index(ip)
                        device_name = self.device_names[idx]
                        if device_name.strip():
                            futures[executor.submit(self.ping_host, device_name, 8)] = (ip, device_name)
                    except ValueError:
                        continue

                for future in tqdm(as_completed(futures), total=len(futures)):
                    (ip, device_name) = futures[future]
                    _, result = future.result()
                    if result == "alive":
                        self.ping_results[ip] = "alive"  # ä»¥ IP ç‚º key æ›´æ–°ç‹€æ…‹
                        success_by_device.append((ip, device_name))
                    else:
                        fail_by_device.append((ip, device_name))

            # â˜… ç¬¬ä¸‰è¼ªå…¨éƒ¨å®Œæˆå¾Œï¼Œæ‰ä¸€æ¬¡æ€§è¼¸å‡ºå½™æ•´ log
            if success_by_device:
                logging.info("âœ… ç¬¬ä¸‰è¼ª Device_Name æˆåŠŸæ›¿ä»£æ¸…å–®ï¼ˆå…± %d ç­†ï¼‰ï¼š", len(success_by_device))
                for ip, dev in success_by_device:
                    logging.info("  - Device_Name=%s æ›¿ä»£ IP=%s â†’ alive", dev, ip)
            if fail_by_device:
                logging.warning("âŒ ç¬¬ä¸‰è¼ª Device_Name ä»ç„¡å›æ‡‰æ¸…å–®ï¼ˆå…± %d ç­†ï¼‰ï¼š", len(fail_by_device))
                for ip, dev in fail_by_device:
                    logging.warning("  - Device_Name=%s æ›¿ä»£ IP=%s â†’ dead", dev, ip)

    def update_csv_with_alive_status(self):
        rows = []
        with open(self.file_path, mode='r', encoding='utf-8-sig') as file:
            reader = csv.reader(file)
            header = next(reader)

            # å¦‚æœæœ‰ alive_or_dead æ¬„ä½ï¼Œå…ˆæ‰¾åˆ° index ä¸¦å¾æ¯è¡Œä¸­åˆªé™¤
            if 'alive_or_dead' in header:
                index_to_remove = header.index('alive_or_dead')
                header.pop(index_to_remove)
            else:
                index_to_remove = None  # æ²’æœ‰ä¹Ÿ ok

            header.append('alive_or_dead')
            rows.append(header)

            for row in reader:
                if index_to_remove is not None and len(row) > index_to_remove:
                    row.pop(index_to_remove)  # åˆªé™¤èˆŠçš„ alive_or_dead æ¬„ä½

                ip_address = row[0]
                status = self.ping_results.get(ip_address, "dead")
                row.append(status)
                rows.append(row)

        with open(self.file_path, mode='w', encoding='utf-8-sig', newline='') as file:
            writer = csv.writer(file)
            writer.writerows(rows)


    def display_results(self):
        formatted_devices = []
        pingable_formatted_devices = []

        for ip, device_name in zip(self.ip_addresses, self.device_names):
            if re.match(r'\d{8}-W\d{2,3}', device_name):
                formatted_devices.append((ip, device_name))
                if self.ping_results.get(ip) == "alive":
                    pingable_formatted_devices.append(ip)

        total_pingable = list(ip for ip, status in self.ping_results.items() if status == "alive")
        return len(total_pingable), len(formatted_devices), len(pingable_formatted_devices)


def write_error_task(file_path):
    lock_path = file_path + ".lock"
    json_lock_path = r"\\20220530-w03\Data\EAP_Health_level\error_data\error_lose_ipcount.json.lock"

    try:
        df = pd.read_csv(file_path, encoding='utf-8-sig')


        filtered_df = df[
            (df["alive_or_dead"].astype(str).str.lower() == "dead") &    
            (df["Machine_ID"].notna()) & 
            (df["Machine_ID"].astype(str).str.strip() != '')  
        ]

        if filtered_df.empty:
            logging.info(f"âš ï¸ ç„¡ç¬¦åˆæ¢ä»¶è³‡æ–™ï¼Œç•¥éï¼š{file_path}")
            return

        # file_place = filtered_df["File_Place"].iloc[0]
        current_file_name = os.path.basename(file_path)
        file_place = current_file_name

        # å…ˆé‡å°æ¯å€‹åˆ†é¡åšåˆ‡åˆ†
        categories = ['EAP', 'EQP', 'Switch']

        for category in categories:
            category_df = filtered_df[filtered_df['Category'].astype(str).str.strip() == category]
            
            if category_df.empty:
                continue 

            # csv_output_path = r"\\20220530-w03\Data\EAP_Health_level\error_data\error_lose_machine.csv"
            csv_output_path = rf"\\20220530-w03\Data\EAP_Health_level\error_data\error_lose_machine_{category}.csv"

            with FileLock(csv_output_path + ".lock", timeout=30):
                if os.path.exists(csv_output_path):
                    existing_df = pd.read_csv(csv_output_path, encoding='utf-8-sig')
                    # existing_df = existing_df[existing_df["File_Place"] != file_place]
                    combined_df = pd.concat([existing_df, category_df], ignore_index=True)
                    updated_df = combined_df.drop_duplicates(subset=["Internal_IP", "Machine_ID"])
                    # updated_df = pd.concat([existing_df, category_df], ignore_index=True)
                else:
                    updated_df = category_df

                updated_df.to_csv(csv_output_path, index=False, encoding='utf-8-sig')
                logging.info(f"âœ… å·²æ›´æ–° {csv_output_path}ï¼Œæ’é™¤é‡è¤‡çš„ File_Placeï¼š{file_place}")
                
        # JSON å¯«å…¥åŠ é–
        today_str = datetime.now().strftime("%Y%m%d")
        ip_count_path = rf"\\20220530-w03\Data\EAP_Health_level\error_data\Daily_error\error_lose_ipcount_{today_str}.json"


        df = pd.read_csv(file_path, encoding='utf-8-sig')
        # æ‰€ä»¥æ­£ç¢ºåšæ³•æ˜¯ï¼šç›´æ¥æŠ“å‡ºç¬¬ä¸€å€‹ Internal_IP == '0' é‚£è¡Œ
        cutoff_rows = df[
            df["Internal_IP"].astype(str).str.strip() == "0"
        ]

        if not cutoff_rows.empty:
            cutoff_index = cutoff_rows.index[0]
            df = df.iloc[:cutoff_index]  # ä¿ç•™ 0 å‡ºç¾å‰çš„æ‰€æœ‰è³‡æ–™

        filtered_df = df[
            (df["alive_or_dead"].astype(str).str.lower().str.strip() == "dead") & 
            (df["Machine_ID"].notna()) & 
            (df["Machine_ID"].astype(str).str.strip() != '')  
        ]


        with FileLock(json_lock_path, timeout=30):
            if os.path.exists(ip_count_path):
                with open(ip_count_path, "r", encoding="utf-8-sig") as f:
                    try:
                        ip_loss_data = json.load(f)
                    except json.JSONDecodeError:
                        ip_loss_data = {}
            else:
                ip_loss_data = {}

            if file_place not in ip_loss_data:
                ip_loss_data[file_place] = {}

        for _, row in filtered_df.iterrows():
            ip = str(row["Internal_IP"]).strip()
            machine = str(row["Machine_ID"]).strip()
            
            # æª¢æŸ¥ IP ç„¡æ•ˆ
            if ip in ["", "0", "nan"]:
                continue

            # æª¢æŸ¥ Machine_ID ç„¡æ•ˆ
            if machine in ["", "0", "nan"]:
                continue

            if machine not in ip_loss_data[file_place]:
                ip_loss_data[file_place][ip] = {
                    "ip": ip,
                    "machine": machine,
                    "count": 1
                }
            else:
                ip_loss_data[file_place][ip]["count"] += 1

        with open(ip_count_path, "w", encoding="utf-8-sig") as f:
            json.dump(ip_loss_data, f, ensure_ascii=False, indent=4)

        logging.info(f"âœ… å·²æ›´æ–° IP loss è¨ˆæ•¸æª”æ¡ˆï¼š{ip_count_path}")

    except Timeout:
        logging.error(f"âŒ æª”æ¡ˆé–å–å¾—å¤±æ•—ï¼ˆè¢«å…¶ä»–ç¨‹å¼ä½”ç”¨ä¸­ï¼‰ï¼š{lock_path} æˆ– {json_lock_path}")





def backup_csv_before_ping(csv_path):
    """
    å‚™ä»½ CSV æª”æ¡ˆï¼Œä¿ç•™ 5 ä»½å‚™ä»½ï¼ˆbackup_1 åˆ° backup_5ï¼‰
    æ”¾åœ¨å„è‡ªçš„æª”åè³‡æ–™å¤¾ä¸­
    
    å‚™ä»½è¼ªæ›¿ï¼š
    - backup_5 è¢«åˆªé™¤
    - backup_4 â†’ backup_5
    - backup_3 â†’ backup_4
    - backup_2 â†’ backup_3
    - backup_1 â†’ backup_2
    - åŸå§‹æª” â†’ backup_1
    """
    file_name = os.path.basename(csv_path)
    file_name_without_ext = os.path.splitext(file_name)[0]
    
    # å»ºç«‹æª”åå°ˆå±¬è³‡æ–™å¤¾
    backup_dir = os.path.join(BASE_DIR, "backups", file_name_without_ext)
    os.makedirs(backup_dir, exist_ok=True)
    
    logging.info(f"ğŸ“¦ é–‹å§‹å‚™ä»½ CSVï¼š{file_name}")
    
    # å‚™ä»½æª”æ¡ˆè·¯å¾‘
    backup_files = [os.path.join(backup_dir, f"backup_{i}.csv") for i in range(1, 6)]
    
    # è¼ªæ›¿å‚™ä»½ï¼šå¾å¾Œå¾€å‰
    # åˆªé™¤æœ€èˆŠçš„ backup_5
    if os.path.exists(backup_files[4]):
        try:
            os.remove(backup_files[4])
            logging.info(f"ğŸ—‘ï¸ å·²åˆªé™¤æœ€èˆŠçš„å‚™ä»½ï¼šbackup_5.csv")
        except Exception as e:
            logging.error(f"âŒ åˆªé™¤ backup_5 å¤±æ•—ï¼š{e}")
    
    # backup_4 â†’ backup_5, backup_3 â†’ backup_4, ..., backup_1 â†’ backup_2
    for i in range(4, 0, -1):
        if os.path.exists(backup_files[i-1]):
            try:
                os.rename(backup_files[i-1], backup_files[i])
                logging.info(f"ğŸ“ å·²å°‡ backup_{i} æ”¹åç‚º backup_{i+1}")
            except Exception as e:
                logging.error(f"âŒ backup_{i} â†’ backup_{i+1} æ”¹åå¤±æ•—ï¼š{e}")
    
    # è¤‡è£½åŸå§‹æª”ç‚º backup_1
    try:
        shutil.copy2(csv_path, backup_files[0])
        logging.info(f"ğŸ“‹ å·²è¤‡è£½åŸå§‹ CSV ç‚º backup_1.csv")
    except Exception as e:
        logging.error(f"âŒ è¤‡è£½ CSV å¤±æ•—ï¼š{e}")
    
    return backup_dir

def check_dead_devices():
    from datetime import datetime
        
    eap_list = []      # EAP è®¾å¤‡åˆ—è¡¨
    eqp_list = []      # EQP è®¾å¤‡åˆ—è¡¨
    switch_list = []   # Switch è®¾å¤‡åˆ—è¡¨
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    logging.info(f"========== å¼€å§‹æ£€æŸ¥ Dead è®¾å¤‡ ==========")
    logging.info(f"BASE_DIR: {BASE_DIR}")
    logging.info(f"file_path å…±æœ‰ {len(file_path)} ä¸ªæ¡£æ¡ˆ")
    
    for i, path in enumerate(file_path):
        logging.info(f"--- æ¡£æ¡ˆ {i+1}/{len(file_path)} ---")
        logging.info(f"è·¯å¾„: {path}")
        
        if not os.path.exists(path):
            logging.warning(f"âš ï¸ æ¡£æ¡ˆä¸å­˜åœ¨: {path}")
            continue
            
        file_name = os.path.basename(path)
        file_name_without_ext = os.path.splitext(file_name)[0]
        
        # å»ºç«‹å¤‡ä»½èµ„æ–™å¤¹è·¯å¾„
        backup_dir = os.path.join(BASE_DIR, "backups", file_name_without_ext)
        
        # 5 ä»½å¤‡ä»½æ¡£æ¡ˆè·¯å¾„
        backup_1_file = os.path.join(backup_dir, "backup_1.csv")
        backup_2_file = os.path.join(backup_dir, "backup_2.csv")
        backup_3_file = os.path.join(backup_dir, "backup_3.csv")
        backup_4_file = os.path.join(backup_dir, "backup_4.csv")
        backup_5_file = os.path.join(backup_dir, "backup_5.csv")
        
        logging.info(f"æ¡£æ¡ˆå­˜åœ¨: True")
        logging.info(f"å¤‡ä»½èµ„æ–™å¤¹: {backup_dir}")
        
        # æ£€æŸ¥å¤‡ä»½æ¡£æ¡ˆæ˜¯å¦å­˜åœ¨
        backup_1_exists = os.path.exists(backup_1_file)
        backup_2_exists = os.path.exists(backup_2_file)
        backup_3_exists = os.path.exists(backup_3_file)
        backup_4_exists = os.path.exists(backup_4_file)
        backup_5_exists = os.path.exists(backup_5_file)
        
        logging.info(f"å¤‡ä»½çŠ¶æ€: backup_1={backup_1_exists}, backup_2={backup_2_exists}, backup_3={backup_3_exists}, backup_4={backup_4_exists}, backup_5={backup_5_exists}")
        
        # è¯»å–å½“å‰åŸå§‹ CSV
        try:
            current_df = pd.read_csv(path, encoding='utf-8-sig')
            current_status = dict(zip(
                current_df['Internal_IP'].astype(str), 
                current_df['alive_or_dead'].astype(str).str.lower().str.strip()
            ))
            
            logging.info(f"ğŸ” æ£€æŸ¥æ¡£æ¡ˆï¼š{file_name}")
            logging.info(f"   åŸå§‹ CSV: {path}")
            logging.info(f"   åŸå§‹ç¬”æ•°: {len(current_df)}")
            
        except Exception as e:
            logging.error(f"âŒ è¯»å–åŸå§‹ CSV å¤±è´¥ {file_name}ï¼š{e}")
            continue
        
        # è¯»å–æ‰€æœ‰å¤‡ä»½çš„çŠ¶æ€
        backup_1_status = {}
        backup_2_status = {}
        backup_3_status = {}
        backup_4_status = {}
        backup_5_status = {}
        
        if backup_1_exists:
            try:
                backup_1_df = pd.read_csv(backup_1_file, encoding='utf-8-sig')
                backup_1_status = dict(zip(
                    backup_1_df['Internal_IP'].astype(str), 
                    backup_1_df['alive_or_dead'].astype(str).str.lower().str.strip()
                ))
                logging.info(f"   å·²è¯»å– backup_1ï¼Œç¬”æ•°: {len(backup_1_df)}")
            except Exception as e:
                logging.error(f"âŒ è¯»å– backup_1 å¤±è´¥ï¼š{e}")
        
        if backup_2_exists:
            try:
                backup_2_df = pd.read_csv(backup_2_file, encoding='utf-8-sig')
                backup_2_status = dict(zip(
                    backup_2_df['Internal_IP'].astype(str), 
                    backup_2_df['alive_or_dead'].astype(str).str.lower().str.strip()
                ))
                logging.info(f"   å·²è¯»å– backup_2ï¼Œç¬”æ•°: {len(backup_2_df)}")
            except Exception as e:
                logging.error(f"âŒ è¯»å– backup_2 å¤±è´¥ï¼š{e}")
        
        if backup_3_exists:
            try:
                backup_3_df = pd.read_csv(backup_3_file, encoding='utf-8-sig')
                backup_3_status = dict(zip(
                    backup_3_df['Internal_IP'].astype(str), 
                    backup_3_df['alive_or_dead'].astype(str).str.lower().str.strip()
                ))
                logging.info(f"   å·²è¯»å– backup_3ï¼Œç¬”æ•°: {len(backup_3_df)}")
            except Exception as e:
                logging.error(f"âŒ è¯»å– backup_3 å¤±è´¥ï¼š{e}")
        
        if backup_4_exists:
            try:
                backup_4_df = pd.read_csv(backup_4_file, encoding='utf-8-sig')
                backup_4_status = dict(zip(
                    backup_4_df['Internal_IP'].astype(str), 
                    backup_4_df['alive_or_dead'].astype(str).str.lower().str.strip()
                ))
                logging.info(f"   å·²è¯»å– backup_4ï¼Œç¬”æ•°: {len(backup_4_df)}")
            except Exception as e:
                logging.error(f"âŒ è¯»å– backup_4 å¤±è´¥ï¼š{e}")
        
        if backup_5_exists:
            try:
                backup_5_df = pd.read_csv(backup_5_file, encoding='utf-8-sig')
                backup_5_status = dict(zip(
                    backup_5_df['Internal_IP'].astype(str), 
                    backup_5_df['alive_or_dead'].astype(str).str.lower().str.strip()
                ))
                logging.info(f"   å·²è¯»å– backup_5ï¼Œç¬”æ•°: {len(backup_5_df)}")
            except Exception as e:
                logging.error(f"âŒ è¯»å– backup_5 å¤±è´¥ï¼š{e}")
        
        # å¯¹æ¯ä¸ª IP è¿›è¡Œæ£€æŸ¥
        for ip, current in current_status.items():
            # è·å–è¯¥ IP åœ¨å„ä¸ª backup çš„çŠ¶æ€
            backup_1 = backup_1_status.get(ip, "")
            backup_2 = backup_2_status.get(ip, "")
            backup_3 = backup_3_status.get(ip, "")
            backup_4 = backup_4_status.get(ip, "")
            backup_5 = backup_5_status.get(ip, "")
            
            # è·å–è¯¥ IP çš„ Category å’Œ Machine_ID
            try:
                ip_row = current_df[current_df['Internal_IP'].astype(str) == ip]
                if ip_row.empty:
                    continue
                
                category = str(ip_row['Category'].values[0]).strip().upper()
                machine_id = str(ip_row['Machine_ID'].values[0]).strip()
                
                # åˆ†ç±»ç­›é€‰é€»è¾‘
                if category in ['EAP', 'EQP']:
                    # EAP/EQPï¼šåªè®°å½•æœ‰ Machine_ID çš„
                    if machine_id in ['', 'nan', 'None']:
                        continue
                elif category == 'SWITCH':
                    # Switchï¼šä¸ç®¡ Machine_IDï¼Œå…¨éƒ¨è®°å½•
                    pass
                else:
                    # å…¶ä»–ç±»åˆ«ï¼šè·³è¿‡
                    continue
                
            except Exception as e:
                logging.error(f"   IP {ip}: è¯»å– Category/Machine_ID å¤±è´¥ï¼š{e}")
                continue
            
            # æ ¹æ® Category å¥—ç”¨ä¸åŒçš„æ£€æŸ¥è§„åˆ™
            if category == 'EAP':
                # EAP è§„åˆ™ï¼šcurrent=dead AND (ä»»ä¸€ backup=dead)
                if current == "dead" and (backup_1 == "dead" or backup_2 == "dead" or backup_3 == "dead" or backup_4 == "dead" or backup_5 == "dead"):
                    eap_list.append((current_time, ip, file_name))
                    logging.error(f"ğŸš¨ {file_name} - {ip} (EAP): current=dead and (backup_1={backup_1} or backup_2={backup_2} or backup_3={backup_3} or backup_4={backup_4} or backup_5={backup_5})")
            
            elif category == 'EQP':
                # EQP è§„åˆ™ï¼šcurrent=dead AND (ä»»ä¸€ backup=dead)
                if current == "dead" and (backup_1 == "dead" or backup_2 == "dead" or backup_3 == "dead" or backup_4 == "dead" or backup_5 == "dead"):
                    eqp_list.append((current_time, ip, file_name))
                    logging.error(f"ğŸš¨ {file_name} - {ip} (EQP): current=dead and (backup_1={backup_1} or backup_2={backup_2} or backup_3={backup_3} or backup_4={backup_4} or backup_5={backup_5})")
            
            elif category == 'SWITCH':
                # Switch è§„åˆ™ï¼šcurrent=dead AND (ä»»ä¸€ backup=alive)
                if current == "dead" and (backup_1 == "alive" or backup_2 == "alive" or backup_3 == "alive" or backup_4 == "alive" or backup_5 == "alive"):
                    switch_list.append((current_time, ip, file_name))
                    logging.error(f"ğŸš¨ {file_name} - {ip} (Switch): current=dead and (backup_1={backup_1} or backup_2={backup_2} or backup_3={backup_3} or backup_4={backup_4} or backup_5={backup_5})")
    
    # è¾“å‡ºåˆ° ../EAP.txt
    if eap_list:
        eap_path = os.path.join(BASE_DIR, "..", "EAP.txt")
        try:
            with open(eap_path, 'a', encoding='utf-8') as f:
                for time_str, ip, source in eap_list:
                    f.write(f"{time_str} | {ip} | {source}\n")
            logging.info(f"âœ… å·²å°† {len(eap_list)} ç¬” EAP è®¾å¤‡å†™å…¥ï¼š{eap_path}")
        except Exception as e:
            logging.error(f"âŒ å†™å…¥ EAP.txt å¤±è´¥ï¼š{e}")
    else:
        logging.info("âœ… æ—  EAP è¿ç»­ dead è®¾å¤‡")
    
    # è¾“å‡ºåˆ° ../EQP.txt
    if eqp_list:
        eqp_path = os.path.join(BASE_DIR, "..", "EQP.txt")
        try:
            with open(eqp_path, 'a', encoding='utf-8') as f:
                for time_str, ip, source in eqp_list:
                    f.write(f"{time_str} | {ip} | {source}\n")
            logging.info(f"âœ… å·²å°† {len(eqp_list)} ç¬” EQP è®¾å¤‡å†™å…¥ï¼š{eqp_path}")
        except Exception as e:
            logging.error(f"âŒ å†™å…¥ EQP.txt å¤±è´¥ï¼š{e}")
    else:
        logging.info("âœ… æ—  EQP è¿ç»­ dead è®¾å¤‡")
    
    # è¾“å‡ºåˆ° ../Switch.txt
    if switch_list:
        switch_path = os.path.join(BASE_DIR, "..", "Switch.txt")
        try:
            with open(switch_path, 'a', encoding='utf-8') as f:
                for time_str, ip, source in switch_list:
                    f.write(f"{time_str} | {ip} | {source}\n")
            logging.info(f"âœ… å·²å°† {len(switch_list)} ç¬” Switch è®¾å¤‡å†™å…¥ï¼š{switch_path}")
        except Exception as e:
            logging.error(f"âŒ å†™å…¥ Switch.txt å¤±è´¥ï¼š{e}")
    else:
        logging.info("âœ… æ—  Switch ä» alive å˜ dead è®¾å¤‡")
    
    
    
    for i, path in enumerate(file_path):
        logging.info(f"--- æª”æ¡ˆ {i+1}/{len(file_path)} ---")
        logging.info(f"è·¯å¾‘: {path}")
        
        if not os.path.exists(path):
            logging.warning(f"âš ï¸ æª”æ¡ˆä¸å­˜åœ¨: {path}")
            continue
            
        file_name = os.path.basename(path)
        file_name_without_ext = os.path.splitext(file_name)[0]
        
        # å»ºç«‹å‚™ä»½è³‡æ–™å¤¾è·¯å¾‘
        backup_dir = os.path.join(BASE_DIR, "backups", file_name_without_ext)
        
        # 5 ä»½å‚™ä»½æª”æ¡ˆè·¯å¾‘
        backup_files = [os.path.join(backup_dir, f"backup_{i}.csv") for i in range(1, 6)]
        
        logging.info(f"æª”æ¡ˆå­˜åœ¨: True")
        logging.info(f"å‚™ä»½è³‡æ–™å¤¾: {backup_dir}")
        
        # æª¢æŸ¥å‚™ä»½æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        backup_exists = [os.path.exists(f) for f in backup_files]
        logging.info(f"å‚™ä»½ç‹€æ…‹: backup_1={backup_exists[0]}, backup_2={backup_exists[1]}, backup_3={backup_exists[2]}, backup_4={backup_exists[3]}, backup_5={backup_exists[4]}")
        
        # è‡³å°‘éœ€è¦ backup_5ï¼ˆæœ€èˆŠçš„ï¼‰æ‰èƒ½é–‹å§‹æª¢æŸ¥
        if not backup_exists[4]:
            logging.info(f"âš ï¸ å‚™ä»½æª”æ¡ˆä¸å®Œæ•´ï¼ˆéœ€è¦ backup_5ï¼‰ï¼Œè·³éï¼š{file_name}")
            continue
            
        try:
            # è®€å–ç•¶å‰åŸå§‹ CSV
            current_df = pd.read_csv(path, encoding='utf-8-sig')
            
            # è®€å– backup_5ï¼ˆæœ€èˆŠçš„å‚™ä»½ï¼‰
            backup_5_df = pd.read_csv(backup_files[4], encoding='utf-8-sig')
            
            logging.info(f"ğŸ” æª¢æŸ¥æª”æ¡ˆï¼š{file_name}")
            logging.info(f"   backup_5 CSV: {backup_files[4]}")
            logging.info(f"   åŸå§‹ CSV: {path}")
            logging.info(f"   backup_5 ç­†æ•¸: {len(backup_5_df)}, åŸå§‹ç­†æ•¸: {len(current_df)}")
            
            # è®€å–æ‰€æœ‰å‚™ä»½çš„ç‹€æ…‹ï¼ˆç”¨æ–¼ Switch æª¢æŸ¥ï¼‰
            all_backup_status = []
            for j, backup_file in enumerate(backup_files):
                if backup_exists[j]:
                    try:
                        backup_df = pd.read_csv(backup_file, encoding='utf-8-sig')
                        backup_status = dict(zip(
                            backup_df['Internal_IP'].astype(str), 
                            backup_df['alive_or_dead'].astype(str).str.lower().str.strip()
                        ))
                        all_backup_status.append(backup_status)
                    except Exception as e:
                        logging.error(f"âŒ è®€å– backup_{j+1} å¤±æ•—ï¼š{e}")
                        all_backup_status.append({})
                else:
                    all_backup_status.append({})
             
            # backup_5 ç‹€æ…‹ï¼ˆæœ€èˆŠçš„ï¼‰
            backup_5_status = dict(zip(
                backup_5_df['Internal_IP'].astype(str), 
                backup_5_df['alive_or_dead'].astype(str).str.lower().str.strip()
            ))
                
            # ç•¶å‰ç‹€æ…‹
            current_status = dict(zip(
                current_df['Internal_IP'].astype(str), 
                current_df['alive_or_dead'].astype(str).str.lower().str.strip()
            ))
            
            # Debug: é¡¯ç¤ºå‰å¹¾ç­†è³‡æ–™
            logging.info(f"   backup_5 å‰3ç­† IP ç‹€æ…‹: {dict(list(backup_5_status.items())[:3])}")
            logging.info(f"   åŸå§‹å‰3ç­† IP ç‹€æ…‹: {dict(list(current_status.items())[:3])}")
                
            for ip, current in current_status.items():
                backup_5 = backup_5_status.get(ip, "")
                
                # ç²å–è©² IP çš„ Category å’Œ Machine_ID
                try:
                    ip_row = current_df[current_df['Internal_IP'].astype(str) == ip]
                    if ip_row.empty:
                        logging.debug(f"   IP {ip}: æ‰¾ä¸åˆ°å°æ‡‰çš„è³‡æ–™ï¼Œè·³é")
                        continue
                    
                    category = str(ip_row['Category'].values[0]).strip().upper()
                    machine_id = str(ip_row['Machine_ID'].values[0]).strip()
                    
                    # åˆ†é¡ç¯©é¸é‚è¼¯
                    if category in ['EAP', 'EQP']:
                        # EAP/EQPï¼šåªè¨˜éŒ„æœ‰ Machine_ID çš„
                        if machine_id in ['', 'nan', 'None']:
                            logging.debug(f"   IP {ip}: {category} ä½† Machine_ID ç‚ºç©ºï¼Œè·³é")
                            continue
                        logging.debug(f"   IP {ip}: {category}, Machine_ID={machine_id}, ç¬¦åˆæ¢ä»¶")
                    elif category == 'SWITCH':
                        # Switchï¼šä¸ç®¡ Machine_IDï¼Œå…¨éƒ¨è¨˜éŒ„
                        logging.debug(f"   IP {ip}: Switch, ä¸æª¢æŸ¥ Machine_ID")
                    else:
                        # å…¶ä»–é¡åˆ¥ï¼šè·³é
                        logging.debug(f"   IP {ip}: Category={category}, ä¸åœ¨ EAP/EQP/Switch ç¯„åœï¼Œè·³é")
                        continue
                    
                except Exception as e:
                    logging.error(f"   IP {ip}: è®€å– Category/Machine_ID å¤±æ•—ï¼š{e}")
                    continue
                
                # Debug: é¡¯ç¤ºæ¯å€‹ IP çš„æ¯”å°
                logging.debug(f"   IP {ip}: backup_5={backup_5}, current={current}, category={category}")
                
                # æ ¹æ“š Category å¥—ç”¨ä¸åŒçš„æª¢æŸ¥è¦å‰‡
                should_alarm = False
                target_list = None
                
                if category == 'SWITCH':
                    # Switch ç‰¹åˆ¥è¦å‰‡ï¼šæª¢æŸ¥ä»»ä¸€å‚™ä»½ä¸­æ˜¯å¦æœ‰ aliveï¼Œä¸”ç•¶å‰æ˜¯ dead
                    has_alive_in_backups = any(
                        backup.get(ip, "") == "alive" 
                        for backup in all_backup_status
                    )
                    
                    if current == "dead" and has_alive_in_backups:
                        should_alarm = True
                        target_list = switch_list
                        logging.error(f"ğŸš¨ {file_name} - {ip} (Switch): å¾ alive è®Š deadï¼ˆå‚™ä»½ä¸­æœ‰ alive è¨˜éŒ„ï¼‰")
                    elif current == "dead" and not has_alive_in_backups:
                        # Switch ä¸€ç›´éƒ½æ˜¯ deadï¼Œä¸è¨˜éŒ„
                        logging.debug(f"   IP {ip} (Switch): ä¸€ç›´éƒ½æ˜¯ deadï¼Œä¸è¨˜éŒ„")
                elif category == 'EAP':
                    # EAP è¦å‰‡ï¼šbackup_5=dead AND current=dead
                    if backup_5 == "dead" and current == "dead":
                        should_alarm = True
                        target_list = eap_list
                        logging.error(f"ğŸš¨ {file_name} - {ip} (EAP): é€£çºŒ dead (backup_5={backup_5}, current={current})")
                elif category == 'EQP':
                    # EQP è¦å‰‡ï¼šbackup_5=dead AND current=dead
                    if backup_5 == "dead" and current == "dead":
                        should_alarm = True
                        target_list = eqp_list
                        logging.error(f"ğŸš¨ {file_name} - {ip} (EQP): é€£çºŒ dead (backup_5={backup_5}, current={current})")
                
                # å¯«å…¥å°æ‡‰çš„ list
                if should_alarm and target_list is not None:
                    target_list.append((current_time, ip, file_name))
             
        except Exception as e:
            logging.error(f"âŒ æ¯”å°å¤±æ•— {file_name}ï¼š{e}")
            import traceback
            logging.error(traceback.format_exc())
    
    # è¼¸å‡ºåˆ° ../EAP.txt
    if eap_list:
        eap_path = os.path.join(BASE_DIR, "..", "EAP.txt")
        try:
            with open(eap_path, 'a', encoding='utf-8') as f:
                for time_str, ip, source in eap_list:
                    f.write(f"{time_str} | {ip} | {source}\n")
            logging.info(f"âœ… å·²å°‡ {len(eap_list)} ç­† EAP è¨­å‚™å¯«å…¥ï¼š{eap_path}")
        except Exception as e:
            logging.error(f"âŒ å¯«å…¥ EAP.txt å¤±æ•—ï¼š{e}")
    else:
        logging.info("âœ… ç„¡ EAP é€£çºŒ dead è¨­å‚™")
    
    # è¼¸å‡ºåˆ° ../EQP.txt
    if eqp_list:
        eqp_path = os.path.join(BASE_DIR, "..", "EQP.txt")
        try:
            with open(eqp_path, 'a', encoding='utf-8') as f:
                for time_str, ip, source in eqp_list:
                    f.write(f"{time_str} | {ip} | {source}\n")
            logging.info(f"âœ… å·²å°‡ {len(eqp_list)} ç­† EQP è¨­å‚™å¯«å…¥ï¼š{eqp_path}")
        except Exception as e:
            logging.error(f"âŒ å¯«å…¥ EQP.txt å¤±æ•—ï¼š{e}")
    else:
        logging.info("âœ… ç„¡ EQP é€£çºŒ dead è¨­å‚™")
    
    # è¼¸å‡ºåˆ° ../Switch.txt
    if switch_list:
        switch_path = os.path.join(BASE_DIR, "..", "Switch.txt")
        try:
            with open(switch_path, 'a', encoding='utf-8') as f:
                for time_str, ip, source in switch_list:
                    f.write(f"{time_str} | {ip} | {source}\n")
            logging.info(f"âœ… å·²å°‡ {len(switch_list)} ç­† Switch è¨­å‚™å¯«å…¥ï¼š{switch_path}")
        except Exception as e:
            logging.error(f"âŒ å¯«å…¥ Switch.txt å¤±æ•—ï¼š{e}")
    else:
        logging.info("âœ… ç„¡ Switch å¾ alive è®Š dead è¨­å‚™")
    





if __name__ == '__main__':
    import time

    # file_path = 'K11\\3F\\K11-3F å€ç¶²(27).csv'
    # file_path = [
    #     # å…¶ä»–
    #     r"\\20220530-w03\Data\EAP_Health_level\source\å…¶ä»–\å…¶ä»– å€ç¶²(10).csv", 
    #     # æ­²ä¿®è¡¨
    #     r"\\20220530-w03\Data\EAP_Health_level\source\suixiu.csv", 
    # ]

    file_path = SOURCE_FILES


    # start_time = time.time()

    # for path in file_path:
    #     if not os.path.exists(path):
    #         print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨ï¼š{path}")
    #         continue

    #     logging.info(f"âœ… {path} - æª”æ¡ˆå­˜åœ¨ï¼Œå¯ä»¥è®€å–ï¼")

    #     backup_csv_before_ping(path)

    #     ping_eap = Ping_EAP(path)
    #     ping_eap.read_ip_addresses_from_csv()
    #     ping_eap.scan_all()

    #     total_pingable, formatted_count, formatted_pingable = ping_eap.display_results()
    #     ping_eap.update_csv_with_alive_status()

    #     with open(path, mode='r', encoding='utf-8-sig') as f:
    #         total_lines = len(f.readlines()) - 1

    #     # logging.info(f"ğŸ“Š æˆåŠŸ Ping æ•¸: {total_pingable} / {total_lines} ({total_pingable / total_lines * 100:.2f}%)")
    #     # logging.info(f"ğŸ¯ ç¬¦åˆæ ¼å¼ä¸”æˆåŠŸ Ping: {formatted_pingable} / {formatted_count} ({formatted_pingable / formatted_count * 100:.2f}%)")
    #     # æˆåŠŸ ping æ•¸çµ±è¨ˆ
    #     if total_lines > 0:
    #         success_ratio = total_pingable / total_lines * 100
    #         logging.info(f"ğŸ“Š æˆåŠŸ Ping æ•¸: {total_pingable} / {total_lines} ({success_ratio:.2f}%)")
    #     else:
    #         logging.info("ğŸ“Š æˆåŠŸ Ping æ•¸: ç„¡è³‡æ–™è¡Œå¯ä¾›è¨ˆç®—ã€‚")

    #     # æ ¼å¼ç¬¦åˆä¸”æˆåŠŸ ping çµ±è¨ˆ
    #     if formatted_count > 0:
    #         formatted_ratio = formatted_pingable / formatted_count * 100
    #         logging.info(f"ğŸ¯ ç¬¦åˆæ ¼å¼ä¸”æˆåŠŸ Ping: {formatted_pingable} / {formatted_count} ({formatted_ratio:.2f}%)")
    #     else:
    #         logging.info("ğŸ¯ ç„¡ç¬¦åˆæ ¼å¼çš„è¨­å‚™ï¼ˆè£ç½®åç¨±ä¸ç¬¦åˆæ­£å‰‡æ¢ä»¶ï¼‰ï¼Œç•¥éçµ±è¨ˆã€‚")

    #     df = pd.read_csv(path, encoding='utf-8-sig')
    #     write_error_task(path)

    # logging.info(f"âœ… ä»»å‹™å®Œæˆï¼Œè€—æ™‚ {time.time() - start_time:.2f} ç§’")

    check_dead_devices()